#!/bin/ksh
#

# Change History


#


## COMMON FUNCTION SCRIPT
## This script aggregates functions from existing Oracle scripts.
## It is to be sourced to use the standard functions.

## NOTE
## 1. The variable TRAP_FILE_LIST had temp files/logs created in orascripts.env (this script).
##    The variable TRAP_FILE_LIST1 has temp files/logs created in your script that need to be
##    removed on a trapped exit (EXIT STOP INT TERM KILL)
## 2. This script has to be sourced before oracle env
##    (current_directory/oracle.<env/instance>)
## 3. If the DEBUG=1 option is turned on please ensure the file
##    /current_directory/oracle/bin/debug_dbamaillist is present and oracle readable.
## 4. export FUNC_DEBUG=1 to debug the functions.

## START # Setup Variables #
##
## Command Variables ##
##
typeset OSTYPE=`uname`
typeset HOST=`uname -n|sed 's/-//g'`
typeset UNIXHOSTS=/etc/hosts

# this is a fix for running this directly from the command line.
if [ "$0" = "/usr/bin/ksh" -o "$0" = "-ksh" ]
then
    typeset PROGRAM_NAME=ksh
    typeset PROGRAM_BASE_SH=ksh
else
    typeset PROGRAM_NAME=`basename ${0}`
    typeset PROGRAM_BASE_SH=`basename ${0} .sh`
fi

##
## BIN  Variables ##
##
typeset CUR_DIR=`pwd`
typeset BB_DATA=${CUR_DIR}/data
typeset BB_UTIL_BIN_DIR=/opt/bb/bin
typeset UNIX_BIN_DIR=/bin
typeset UNIX_USR_BIN_DIR=/usr/bin
typeset UNIX_UCB_BIN_DIR=/usr/ucb
typeset UNIX_USR_SBIN_DIR=/usr/sbin
typeset UNIX_SBIN_DIR=/sbin
typeset UNIX_USR_LOCAL_BIN_DIR=/usr/local/bin


## Files Variables ##

typeset ORATAB=/etc/oratab
typeset ORCL_LOGDIR=${ORCL_LOGDIR:=${BB_DATA}/oracle/logs}
typeset ORCL_BIN=${ORCL_BIN:=${CUR_DIR}/oracle/bin}
typeset DBEGEN=${CUR_DIR}/dbe/generic
typeset DBEORCL=${CUR_DIR}/dbe/orcl
typeset SQLRES=${ORCL_LOGDIR}/${PROGRAM_NAME}_sqlres.$$
typeset TMP_SQLRES=${ORCL_LOGDIR}/${PROGRAM_NAME}_tmp_sqlres.$$
typeset RESFILE=${ORCL_LOGDIR}/${PROGRAM_NAME}_resfile.$$
typeset TIMEOUT_FILE=${ORCL_LOGDIR}/${PROGRAM_NAME}_timeout_file.$$
typeset TMP_FSTAB=${ORCL_LOGDIR}/${PROGRAM_NAME}_tmp_fstab.$$
typeset TMP_MAILFILE=${ORCL_LOGDIR}/${PROGRAM_NAME}_tmp_mailfile.$$
typeset TMP_TOUCHFILE=${ORCL_LOGDIR}/${PROGRAM_NAME}.touch
typeset TRAP_FILE_LIST="${SQLRES} ${RESFILE} ${TMP_SQLRES} ${TIMEOUT_FILE} ${TMP_FSTAB} ${TMP_MAILFILE} ${TMP_TOUCHFILE}"
typeset TRAP_FILE_LIST1
typeset FSTAB


## Commmand Variables ##

typeset DF_K="df -k"
typeset NFS_EXPR=nfs
typeset PS_COMMAND
typeset AWK=${UNIX_BIN_DIR}/awk
typeset FIND=${UNIX_USR_BIN_DIR}/find
typeset WC=${UNIX_USR_BIN_DIR}/wc
typeset TAIL=${UNIX_USR_BIN_DIR}/tail
typeset HEAD=${UNIX_USR_BIN_DIR}/head
typeset TR=${UNIX_USR_BIN_DIR}/tr
typeset ECHO=${UNIX_BIN_DIR}/echo
typeset DATE=${UNIX_BIN_DIR}/date
typeset CAT=${UNIX_BIN_DIR}/cat
typeset RM=${UNIX_BIN_DIR}/rm
typeset LS=${UNIX_BIN_DIR}/ls
typeset DF=${UNIX_BIN_DIR}/df
typeset MV=${UNIX_BIN_DIR}/mv
typeset GREP=${UNIX_BIN_DIR}/grep
typeset EGREP=${UNIX_BIN_DIR}/egrep
typeset SLEEP=${UNIX_BIN_DIR}/sleep
typeset CP=${UNIX_BIN_DIR}/cp
typeset SED=${UNIX_BIN_DIR}/sed
typeset SU=${UNIX_BIN_DIR}/su
typeset GZIP=${UNIX_BIN_DIR}/gzip
typeset TOUCH=${UNIX_BIN_DIR}/touch
typeset EXPR=${UNIX_USR_BIN_DIR}/expr
typeset WHOAMI=${UNIX_USR_BIN_DIR}/whoami
typeset PS=${UNIX_BIN_DIR}/ps
typeset MOUNT=${UNIX_USR_SBIN_DIR}/mount
typeset FUSER=${UNIX_USR_SBIN_DIR}/fuser
typeset NEWOCCURENCE=${CUR_DIR}/newoccurence
typeset IS_BUSINESSHR=${DBEGEN}/is_working_hours
typeset ISCPUDOWN=${CUR_DIR}/iscpudown.sh
typeset ERRMSGMON=${DBEGEN}/dberrtomsgmon.sh
typeset OERRMSGMON=${DBEORCL}/odberrtomsgmon.sh
typeset ORA_PASSWD=${DBEORCL}/ora_passwd.sh
typeset RSH=${UNIX_USR_BIN_DIR}/rsh
typeset RCP=${UNIX_USR_BIN_DIR}/rcp
typeset PING=${UNIX_USR_SBIN_DIR}/ping
typeset SUDO=${UNIX_USR_LOCAL_BIN_DIR}/sudo
typeset NU=${SUDO}
typeset DBARSH=${DBEGEN}/dbarsh
typeset DBARCP=${DBEGEN}/dbarcp
typeset BBCPULST=${CUR_DIR}/bbcpu.lst
typeset BBCPUALIAS=${CUR_DIR}/bbcpu.alias
typeset ORA_GRIDENV=${CUR_DIR}/oracle.grid
typeset ORA_AGENTENV=${CUR_DIR}/oracle.agent
typeset BBDBAUSER="bbdba"
typeset RMANTNS="rmanhost"
typeset ALLCRONTAB=${DBEGEN}/allcrontab.sh
typeset RTCPU_CPUINFO=${CUR_DIR}/rtcpu_cpuinfo.tsk

case "${OSTYPE}" in
        SunOS)
                WGET=${UNIX_BIN_DIR}/wget
                PS=${UNIX_USR_BIN_DIR}/ps
                AWK=${UNIX_BIN_DIR}/nawk
                WHOAMI=${UNIX_UCB_BIN_DIR}/whoami
                MOUNT=${UNIX_BIN_DIR}/mount
                PS_COMMAND="${PS} -eo comm"
                FSTAB=/etc/vfstab
                ORATAB=/var/opt/oracle/oratab
                # Set flags for echo command to be OS-compliant
                n="-n"; c=""
                ;;
        Linux)
                WGET=${UNIX_USR_BIN_DIR}/wget
                PS_COMMAND="${PS} -eo cmd"
                FSTAB=/etc/fstab
                FUSER=${UNIX_SBIN_DIR}/fuser
                PING="${UNIX_BIN_DIR}/ping -c 1"
                # Set flags for echo command to be OS-compliant
                n="";  c="\c"
                ;;
        AIX)
                WGET=${UNIX_BIN_DIR}/wget
                EXPR=${UNIX_BIN_DIR}/expr
                AWK=${UNIX_BIN_DIR}/nawk
                DF_K="df -Ik"
                NFS_EXPR=nfs3
                PING="${PING} -c 1"
                PS_COMMAND="${PS} -aeo %a"
                ${MOUNT} > ${TMP_FSTAB} 2>/dev/null ; FSTAB=${TMP_FSTAB}
                ;;
esac

##
## Mail Variables ##
##

if [ ! -d "${ORCL_LOGDIR}" ]; then
#    rm -r ${ORCL_LOGDIR}
    mkdir -p ${ORCL_LOGDIR}
#else
#     mkdir -p ${ORCL_LOGDIR}/rat
fi

if [ ! -d "${ORCL_LOGDIR}/rat" ]; then
#    rm -r ${ORCL_LOGDIR}/rat
    mkdir -p ${ORCL_LOGDIR}/rat
#else
#     mkdir -p ${ORCL_LOGDIR}/rat
fi


##
## Mail Variables ##
##
typeset SUBJECT="${PROGRAM_NAME} Error - ${HOST}"
typeset ORACLE_USER="oracle"
typeset ROOT_USER="root"
typeset PROGRAM_USERNAME=`${WHOAMI}`

#
## Oracle Utilities ##
#
typeset SQLPLUS="sqlplus -S"
typeset ORA_EXP=exp
typeset ORA_IMP=imp
typeset ORA_EXPDP=expdp
typeset ORA_IMPDP=impdp


## Oracle/Shell Variables and  Exit Codes ##

typeset -i SUCCESS=0
typeset -i FAILURE=1
typeset -i FAIL_ORA_AUTH=2
typeset -i FAIL_QUERY=3
typeset -i FAIL_TIMEOUT=4
typeset -i FAIL_RC=5
typeset -i ONE_ROW=1
typeset -i NO_ROW=0
typeset -i LAST_RES_COUNT=0
typeset -i SPLUS_PAGESIZE=1000
typeset -i SPLUS_LINESIZE=1000
typeset -i SPLUS_PAGESIZE_0=0
typeset -i SPLUS_SLEEP_COUNTER=0
typeset -i SPLUS_TIMEOUT=${SPLUS_TIMEOUT:=10}               ## In seconds.
typeset -i SPLUS_RC_THRESHOLD=${SPLUS_RC_THRESHOLD:=10000}  ## No. of rows returned.
typeset -i SPLUS_PID                    ## this is the pid of the forked sql*plus.
typeset -i SPLUS_SLEEP_PID              ## this is the pid of the sleep process for sql*plus timeout.
typeset -i RACE_SLEEP_ITER=0            ## this is the counter for the race condition setup.
typeset -i DEBUG=${DEBUG:=0}
typeset -i FUNC_DEBUG=${FUNC_DEBUG:=0}
typeset -i KBYTE=1024
typeset -i DIRSIZE
typeset -i DIRUSED
typeset -i DIRFREE
typeset -i DIRFREE_PERCENT
typeset -i FAIL_DBAMAILLIST=4
typeset -i FAIL_EMAILPROG=5
typeset -i FAIL_NOFILE=5
typeset -i FAIL_NOMAILFILE=6
typeset -i FAIL_PROGRAM_USERNAME=7
typeset -i NODENUM
typeset STD_SPLUS_HEADER="SET FEED OFF PAUSE OFF PAGESIZE ${SPLUS_PAGESIZE_0} LINESIZE ${SPLUS_LINESIZE} HEAD OFF VERI OFF TERM OFF TIME OFF SQLPROMPT'' ;"
typeset SPLUS_LOGIN=""
typeset SPLUS_QUERY=""
typeset LAST_RES_VALUE=""
typeset ORACLE_PASWORD
export PATH=${PATH}:${UNIX_USR_SBIN_DIR}:${UNIX_BIN_DIR}:${UNIX_SBIN_DIR}:${UNIX_USR_LOCAL_BIN_DIR}:${UNIX_USR_BIN_DIR}

# if typeset readonly in other scripts
if [ -z "${ZERO}" ]; then
        ZERO=0
fi

if [ -z "${ONE}" ]; then
        ONE=1
fi

## END # Setup Variables #

## START # Setup Functions #
#
## Function to execute on trap
## files in ${TRAP_FILE_LIST} removed on EXIT STOP INT TERM KILL
## The variable TRAP_FILE_LIST had temp files/logs created in this script.
## The variable TRAP_FILE_LIST1 has temp files/logs created in your script
## that need to be removed on a trapped exit (EXIT STOP INT TERM KILL)
#
function trap_cleanup {
 typeset TRAP_FILE=""

 ((${FUNC_DEBUG})) && {
 for TRAP_FILE in ${TRAP_FILE_LIST}
 do
        ${ECHO} "## ${TRAP_FILE} "
        ${CAT} ${TRAP_FILE}
 done
 }

 ((${FUNC_DEBUG})) && set -xv

 ${RM} -f ${TRAP_FILE_LIST} ${TRAP_FILE_LIST1}
}

#
# function to check for ORACLE errors in the SQL RESULTS file
# ${1} = the SQL RESULTS file to check
#
function chk_sqlres {
 ((${FUNC_DEBUG})) && set -xv

 ((`${GREP} -c 'SP2-' ${1}`)) && return ${FAILURE}
 ((`${GREP} -c 'ORA-' ${1}`)) && return ${FAILURE}
 ((`${GREP} -c 'PLS-' ${1}`)) && return ${FAILURE}
 ((`${GREP} -c 'XOQ-' ${1}`)) && return ${FAILURE}
 ((`${GREP} -c 'RMAN-' ${1}`)) && return ${FAILURE}
 return ${SUCCESS}
}


#
## function to echo and log timestamped messages
## ${1} is the logfile name.
## ${2} is the message
#
function write_log {
 ((${FUNC_DEBUG})) && set -xv

 ${ECHO} "`${DATE} '+%Y/%m/%d %H:%M:%S'` - ${2}" | tee -a ${1}
}

#
# function to validate SQL Connect string
# ${1} userid
# ${2} password
# ${3} tnsname where sql shall be executed
# ${4} output file for concurrent processing (if passed in)
#
function validate_connect_string {
 ((${FUNC_DEBUG})) && set -xv
 typeset SQLRES_PAR

 SPLUS_LOGIN="CONNECT ${1}/${2}@${3}"
 if [[ $# -eq 4 ]]; then
     SQLRES_PAR=$4
 else
     SQLRES_PAR=$TMP_SQLRES
 fi

 ${SQLPLUS} /nolog <<-! > ${SQLRES_PAR} 2>&1
        ${SPLUS_LOGIN};
        SET FEED OFF PAUSE OFF PAGESIZE ${SPLUS_PAGESIZE_0} HEAD OFF VERI OFF LINESIZE ${SPLUS_LINESIZE} TERM OFF TIME OFF DEFINE OFF SQLPROMPT ''
!

 chk_sqlres ${SQLRES_PAR}
 return ${?}
}

#
# function to perform a select and check if the SQL has any return records.
# ${1} user id
# ${2} password
# ${3} tnsname where sql shall be executed
# ${4} SQL statement, pass in with "" and oracle values in ticks ''
# after the execution, ${RESFILE} stores all the results set.
# after the execution, ${LAST_RES_COUNT} stores the number of rows selected
# after the execution, ${LAST_RES_VALUE} stores the value selected
# if there is only 1 row returned.
# ****************************************************************************
# This function returns multiple values. It is recommended to use
#  [ ${?} -ne ${SUCCESS} ] to check for return code from this function
# ****************************************************************************
#
function exec_sql_stmt_no_validate {
 ((${FUNC_DEBUG})) && set -xv
 typeset -i RET_CODE

        SPLUS_QUERY="${4}"

 ${SQLPLUS} ${1}/${2}@${3} AS SYSDBA <<-! > ${SQLRES} 2>&1
        ${STD_SPLUS_HEADER}
        ${SPLUS_QUERY};
!

 chk_sqlres ${SQLRES}
 if [ ${?} -eq ${FAILURE} ]; then
        return ${FAILURE}
 fi

 ${GREP} '[a-zA-Z0-9]' ${SQLRES} | ${EGREP} -v 'rows selected\.$|^Connected\.$' > ${RESFILE}
 LAST_RES_COUNT=`${WC} -l ${RESFILE} | ${AWK} '{print $1}'`

##if [ LAST_RES_COUNT -eq ${ONE_ROW} ]; then
##       LAST_RES_VALUE=`${CAT} ${RESFILE}`
##else
##       LAST_RES_VALUE=""
##fi

 return ${SUCCESS}
}


#
# function to execute a sql statement file - concurrent processing
# ${1} user id
# ${2} password
# ${3} tnsname where sql shall be executed
# ${4} SQL file to be executed
# ${5} file to store results (concurrent processing)
#
function exec_sql_file {
    ((${FUNC_DEBUG})) && set -xv
    typeset SQLRES_PAR

    SQLRES_PAR=${SQLRES}
        SPLUS_QUERY_FILE="${4}"

${SQLPLUS} ${1}/${2}@${3} AS SYSDBA <<-! > ${SQLRES_PAR} 2>&1
        ${STD_SPLUS_HEADER}
        SET TERM ON;
        @${SPLUS_QUERY_FILE};
!

    chk_sqlres ${SQLRES_PAR}
    return ${?}
}

#
## is_dbdwn - function to check if local machine is dbdwnd
## SUCCESS means machines is dbdwnd .
## FAILURE means machine is NOT dbdwnd.
## based on {DRQS 14760953<go>} - marker file in dbdwn
#
function is_dbdwn {
 ((${FUNC_DEBUG})) && set -xv
 typeset DBDWN_MARKER="${CUR_DIR}/dbdwn.done"

 ## check if the file /bb/bin/dbdwn.done exists
 if  [ ! -f ${DBDWN_MARKER} ]; then
        return ${FAILURE}
 fi

 return ${SUCCESS}

}


#
## dirspace - function to check size of a dir
## ${1} Destination
#
function dirspace {
 ((${FUNC_DEBUG})) && set -xv

 typeset RSH=${UNIX_USR_BIN_DIR}/rsh
 typeset DEST=${1}

 DIRSIZE=`${DF_K} ${DEST}|${TAIL} -${ONE}|${AWK} '{print int($(NF-4)/'${KBYTE}')}'`
 DIRUSED=`${DF_K} ${DEST}|${TAIL} -${ONE}|${AWK} '{print int($(NF-3)/'${KBYTE}')}'`
 DIRFREE=`${DF_K} ${DEST}|${TAIL} -${ONE}|${AWK} '{print int($(NF-2)/'${KBYTE}')}'`

 if [ -z "${DIRFREE}" ]; then
        return ${FAILURE}
 fi

 DIRFREE_PERCENT=`${ECHO} "" | ${AWK} -v AWK_DIRFREE=${DIRFREE} -v AWK_DIRSIZE=${DIRSIZE} '{ printf("%0.0f", 100*AWK_DIRFREE/AWK_DIRSIZE)}'`
 return ${SUCCESS}
}

#
## remote_dirspace - function to check size of a remote dir
## ${1} Node
## ${2} Destination Dir.
#
function remote_dirspace {
 ((${FUNC_DEBUG})) && set -xv

 typeset RSH=${UNIX_USR_BIN_DIR}/rsh
 typeset NODE_NAME=${1}
 typeset DEST=${2}
 typeset REMOTE_OS=`${RSH} ${NODE_NAME} "uname"`

 if [ "${REMOTE_OS}" == "AIX" ]; then
        DF_K="df -Ik"
  else
        DF_K="df -k"
 fi

 DIRSIZE=`${RSH} ${NODE_NAME} "${DF_K} ${DEST}"|${TAIL} -${ONE}|${AWK} '{print int($(NF-4)/'${KBYTE}')}'`
 DIRUSED=`${RSH} ${NODE_NAME} "${DF_K} ${DEST}"|${TAIL} -${ONE}|${AWK} '{print int($(NF-3)/'${KBYTE}')}'`
 DIRFREE=`${RSH} ${NODE_NAME} "${DF_K} ${DEST}"|${TAIL} -${ONE}|${AWK} '{print int($(NF-2)/'${KBYTE}')}'`

 if [ -z "${DIRFREE}" ]; then
        return ${FAILURE}
 fi

 DIRFREE_PERCENT=`${ECHO} "" | ${AWK} -v AWK_DIRFREE=${DIRFREE} -v AWK_DIRSIZE=${DIRSIZE} '{ printf("%0.0f", 100*AWK_DIRFREE/AWK_DIRSIZE)}'`
 return ${SUCCESS}
}

#
## is_machine_pingable - function to ping machine (3 tries) and return status.
## ${1} Machine name.
#
function is_machine_pingable {
 ((${FUNC_DEBUG})) && set -xv

 typeset PING_NODE=${1}

 ${PING} ${PING_NODE} > /dev/null 2>&1
 return ${?}

}


#
## source_db_env - function to source Generic Database environment
#

function source_db_env
{
        typeset L_SRV_ENV

        for L_SRV_ENV in oracle.server oracle.server11 oracle.11204 oracle.11203 oracle.client11 oracle.client11_64
        do
                if [ -s ${CUR_DIR}/${L_SRV_ENV} ]; then

                        . ${CUR_DIR}/${L_SRV_ENV}

                        if [ -s ${ORACLE_HOME}/bin/sqlplus ]; then
                                break
                        fi
                fi
        done

        if [ -z "${ORACLE_HOME}" ]; then
                return ${FAILURE}
        fi

        return ${SUCCESS}
}

#
## get_running_sids - function to retrive all the running sids except ASM
##                    in space separated option
#

function get_running_sids
{
        typeset L_RUNNING_SIDS

        L_RUNNING_SIDS=`${PS} -eaf | ${GREP} pmon |  ${GREP} ${PROGRAM_USERNAME} | ${GREP} -v grep | ${GREP} -v ASM | ${AWK} '{print $NF}' | ${AWK} -F"_" '{printf("%s ",$NF)}'`

        if [ ${?} -ne ${SUCCESS} ] ; then
                return ${FAILURE}
        fi

        ${ECHO} ${L_RUNNING_SIDS}
        return ${SUCCESS}
}



#
##  Capture
##
#

function capture
{

if [[ -n "${SOURCE_TNS}" ]]; then # removed to by pass minutes test && ${DURATION} -gt 0
echo "
DECLARE
   l_cursor    DBMS_SQLTUNE.sqlset_cursor;
   vStartTime  Date := sysdate;
   vEndTime    Date := sysdate + ( ${DURATION} / 24 / 60 ) ;
   vCnt        pls_integer;
   vClean      VARCHAR2(30) := '${CLEANUPSQLSETS}' ;
   vCnt_rat    pls_integer;
   vDir  varchar2(2000) := concat('${ORCL_LOGDIR}','/rat');
   vName varchar2(100) ;
BEGIN
--execute immediate 'alter system set \"_cursor_bind_capture_interval\"=300 scope=memory';
select count(*) into vCnt from dba_sqlset where name = '${MYSTS}' and owner='${ORA_USER}';
select count(*) into vCnt_rat from dba_workload_captures where STATUS = 'IN PROGRESS' ;

if vClean = 'YES' and vCnt > 0 then
        dbms_sqltune.DROP_SQLSET('${MYSTS}', user);
end if;

if vCnt_rat > 0 then
    dbms_workload_capture.finish_capture();
end if;

select 'DIR_${MYSTS}' into vName from dual ;
execute immediate 'create or replace directory '||vName||' as '||chr(39)||vDir||chr(39) ;

select count(*) into vCnt from dba_sqlset where name = '${MYSTS}' and owner='${ORA_USER}';
select count(*) into vCnt_rat from dba_workload_captures where STATUS = 'IN PROGRESS' ;

if vCnt = 0 Then
DBMS_SQLTUNE.CREATE_SQLSET(
        sqlset_name => '${MYSTS}',
        sqlset_owner => '${ORA_USER}',
        description => 'STS For 19c Upgrade - SPA');
end if;

if vCnt_rat =0 Then
dbms_workload_capture.start_capture(name => 'CAP_${MYSTS}', dir => 'DIR_${MYSTS}' ,duration => ${DURATION}*60);
end if;

vStartTime := sysdate;
while (vEndTime >= vStartTime)
loop
  OPEN l_cursor FOR
   SELECT VALUE(p)
   FROM   TABLE (DBMS_SQLTUNE.select_cursor_cache ('${FILTER_CLAUSE}',null,null,null,null,1,null,'ALL')) p;
  DBMS_SQLTUNE.load_sqlset (
          sqlset_name    => '${MYSTS}',
          populate_cursor => l_cursor,
          load_option => 'MERGE',
          update_option => 'ACCUMULATE',
          update_attributes => 'ALL',
          sqlset_owner => '${ORA_USER}');
  CLOSE l_cursor;
  commit;
  sys.dbms_lock.sleep(${INTERVAL});
  vStartTime := sysdate;
end loop;

while vCnt_rat > 0 loop
        sys.dbms_lock.sleep(10);
        select count(*) into vCnt_rat from dba_workload_captures where STATUS = 'IN PROGRESS' ;
   end loop;

--execute immediate 'alter system set \"_cursor_bind_capture_interval\"=900 scope=memory';
END;
/
" > ${TEMPFILE}
write_log ${LOGFILE} "Capturing RAT ${SOURCE_TNS} for ${DURATION} Minutes"
write_log ${LOGFILE} "Capturing SQL Tuning Set on ${SOURCE_TNS} for every ${INTERVAL} minutes for ${DURATION} Minutes"
exec_sql_file "${ORA_USER}" "${ORA_PASSWORD}" "${SOURCE_TNS}" "${TEMPFILE}"
if [[ $? -ne ${SUCCESS} ]]; then
        write_log ${LOGFILE} "ERROR: Capturing SQL Tuning Set..and Capturing RAT.."
        cat ${SQLRES} | tee -a ${LOGFILE}
        exit ${FAILURE}
fi
write_log ${LOGFILE} "SQL Tuning Set and RAT captured successfully"
fi

if [[ -n "${SOURCE_TNS}" && "${EXPORTSQLSET}" = "${YESWORD}" ]]; then
        write_log ${LOGFILE} "Creating Staging table to pack SQLTuning Set ${MYSTS} .."
echo "
declare
        vCnt pls_integer := 0;
begin
 select count(*) into vCnt from dba_tables where owner='${ORA_USER}' and table_name='TAB_${MYSTS}';
 if vCnt > 0 then
        execute immediate 'drop table ${ORA_USER}.TAB_${MYSTS} purge' ;
 end if;
 dbms_sqltune.CREATE_STGTAB_SQLSET('TAB_${MYSTS}','${ORA_USER}');
 dbms_sqltune.PACK_STGTAB_SQLSET('${MYSTS}','${ORA_USER}','TAB_${MYSTS}','${ORA_USER}');
-- Temporary Workaround to New Bug with Numeric Overflow error.
 execute immediate 'update ${ORA_USER}.TAB_${MYSTS} set EXECUTIONS = 999999999 where EXECUTIONS > 999999999';
 commit;
end;
/"      > ${TEMPFILE}
        exec_sql_file "${ORA_USER}" "${ORA_PASSWORD}" "${SOURCE_TNS}" "${TEMPFILE}"
                if [[ $? -ne ${SUCCESS} ]]; then
                                write_log ${LOGFILE} "ERROR: Creating TAB_${MYSTS} staging table..."
                                cat ${SQLRES} | tee -a ${LOGFILE}
                exit ${FAILURE}
                fi
        write_log ${LOGFILE} "Successfully created and packed SQLTuning Set ${MYSTS}"
fi

if [[ "${EXPORTSQLSET}" = "${YESWORD}" && -z "${TARGET_TNS}" ]]; then
                exec_sql_stmt_no_validate "${ORA_USER}" "${ORA_PASSWORD}" "${SOURCE_TNS}" "select host_name from v\$instance"
                if [[ $? -ne ${SUCCESS} ]]; then
                                write_log ${LOGFILE} "ERROR: executing sql to get host info for ${SOURCE_TNS}"
                                cat ${SQLRES} | tee -a ${LOGFILE}
                                exit ${FAILURE}
                fi
                SOURCE_HOST=${LAST_RES_VALUE}
echo "
declare
        vDH Number ;
        jstatus varchar2(50);
        vDT varchar2(30) := to_char(sysdate,'YYYYMMDDHH24MISS');
begin
        begin
                sys.utl_file.FREMOVE('LOGDIR','myststab.dmp');
        exception
                when others then
                        null ;
        end;
        vDH := sys.dbms_datapump.open(operation=>'EXPORT',job_mode=>'TABLE',version=>'COMPATIBLE');
        sys.dbms_datapump.metadata_filter(handle=>vDH,name=>'NAME_LIST',value=>'''TAB_${MYSTS}''');
        sys.dbms_datapump.add_file(handle => vDH, filename => 'myststab.dmp',
                                                directory => 'LOGDIR', filetype => SYS.DBMS_DATAPUMP.KU\$_FILE_TYPE_DUMP_FILE);
        sys.dbms_datapump.add_file(handle => vDH, filename => 'myststab_e.log',
                                                 directory => 'LOGDIR', filetype => SYS.DBMS_DATAPUMP.KU\$_FILE_TYPE_LOG_FILE);
        sys.dbms_datapump.start_job(vDH);
        sys.dbms_datapump.wait_for_job(vDH, jstatus);
        if UPPER(jstatus) <> 'COMPLETED' Then
                sys.dbms_datapump.detach(vDH);
                        raise_application_error(-20103, 'ERROR: exporting table ${ORA_USER}.TAB_${MYSTS}');
        end if;
        sys.dbms_datapump.detach(vDH);
end;
/"      > ${TEMPFILE}
        exec_sql_file "${ORA_USER}" "${ORA_PASSWORD}" "${SOURCE_TNS}" "${TEMPFILE}"
        if [[ $? -ne ${SUCCESS} ]]; then
                                write_log ${LOGFILE} "ERROR: exporting table ${ORA_USER}.TAB_${MYSTS} from ${SOURCE_TNS}"
                                cat ${SQLRES} | tee -a ${LOGFILE}
                                exit ${FAILURE}
                fi
        write_log ${LOGFILE} "Successfully exported ${ORA_USER}.TAB_${MYSTS} from ${SOURCE_TNS}"
        write_log ${LOGFILE} "Export Dumpfile : ${ORCL_LOGDIR}/myststab.dmp on ${SOURCE_HOST}"

elif [[ -n "${TARGET_TNS}" && -z "${SOURCE_TNS}" && -n "${DUMPFILE}" ]]; then
        ## possibly Target TNS with dumpfile is used for import and unpack
        write_log ${LOGFILE} "Importing TAB_${MYSTS} using DumpFile ${DUMPFILE}"
echo "
declare
        vDP Number;
        vjstate varchar2(50);
        vFile varchar2(100) := substr('${DUMPFILE}', instr('${DUMPFILE}','/',-1)+1 ) ;
        vDir  varchar2(2000) := substr('${DUMPFILE}', 1, instr('${DUMPFILE}','/',-1)-1 );
        vName varchar2(100) ;
begin
        select 'TEMPDIR_'||substr( sys_guid, 1, 10 ) into vName from dual ;
        execute immediate 'create or replace directory '||vName||' as '||chr(39)||vDir||chr(39) ;
                vDP := sys.dbms_datapump.open(operation => 'IMPORT', job_mode => 'TABLE', version=> 'COMPATIBLE') ;
                -- sys.dbms_datapump.metadata_filter(handle=>vDP,name=>'NAME_LIST',value=>'''TAB_${MYSTS}''');
                sys.dbms_datapump.metadata_filter(handle=>vDP,name=>'NAME_EXPR',value=>' IN (''TAB_${MYSTS}'')');
                sys.dbms_datapump.set_parameter(handle=>vDP, name=>'TABLE_EXISTS_ACTION', value=>'REPLACE') ;
        sys.dbms_datapump.add_file(handle => vDP, filename => vFile,
                                                 directory => vName, filetype => SYS.DBMS_DATAPUMP.KU\$_FILE_TYPE_DUMP_FILE);
                sys.dbms_datapump.add_file(handle => vDP, filename => 'myststab_i.log',
                                                 directory => vName, filetype => SYS.DBMS_DATAPUMP.KU\$_FILE_TYPE_LOG_FILE);
                sys.dbms_datapump.start_job(handle=>vDP);
                sys.dbms_datapump.wait_for_job(handle=>vDP, job_state => vJState);
        execute immediate 'drop directory '||vName ;
                if upper(vJState) <> 'COMPLETED' then
                                sys.dbms_datapump.detach(vDP);
                                raise_application_error(-20101,'ERROR: Importing table TAB_${MYSTS} on ${TARGET_TNS}..');
                end if;
end;
/"      > ${TEMPFILE}
        exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
                if [[ $? -ne ${SUCCESS} ]]; then
                                write_log ${LOGFILE} "ERROR: Importing SQLTuning Set Table using Dumpfile.."
                                cat ${SQLRES} | tee -a ${LOGFILE}
                                exit ${FAILURE}
                fi
                write_log ${LOGFILE} "Successfully Imported ${ORA_USER}.TAB_${MYSTS} table to ${TARGET_TNS}"
echo "
begin
 for i in (select id from DBA_SQLSET_REFERENCES
           where SQLSET_NAME='${MYSTS}' and SQLSET_OWNER='${ORA_USER}')
 loop
        sys.dbms_sqltune.REMOVE_SQLSET_REFERENCE('${MYSTS}', i.id );
 end loop;
 for i in (select name, OWNER from DBA_SQLSET where name = '${MYSTS}' and owner='${ORA_USER}')
 loop
        sys.dbms_sqltune.DELETE_SQLSET(sqlset_name=>i.name,sqlset_owner=>i.owner);
 end loop;
 -- Temporary Workaround to New Bug with Numeric Overflow error.
 execute immediate 'update ${ORA_USER}.TAB_${MYSTS} set EXECUTIONS = 999999999 where EXECUTIONS > 999999999';
 commit;
 sys.dbms_sqltune.unpack_stgtab_sqlset(
                sqlset_name => '${MYSTS}',
                sqlset_owner => '${ORA_USER}',
                replace => true,
                staging_table_name => 'TAB_${MYSTS}',
                staging_schema_owner => '${ORA_USER}');
end;
/"      > ${TEMPFILE}
                exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
                if [[ $? -ne ${SUCCESS} ]]; then
                                write_log ${LOGFILE} "ERROR: Unpacking SQLTuning Set.."
                                cat ${SQLRES} | tee -a ${LOGFILE}
                                exit ${FAILURE}
                fi
                write_log ${LOGFILE} "Successfully Unpacked SQL Tuning Set ${MYSTS} on ${TARGET_TNS}"

elif [[ "${EXPORTSQLSET}" = "${YESWORD}" && -n "${TARGET_TNS}" && -n "${SOURCE_TNS}" ]]; then
        ## possibly source and target info is provided, rcp the file and import the sqlset data
        exec_sql_stmt_no_validate "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "select host_name from v\$instance"
        if [[ $? -ne ${SUCCESS} ]]; then
                write_log ${LOGFILE} "ERROR: executing sql to get host info for ${TARGET_TNS}"
                cat ${SQLRES} | tee -a ${LOGFILE}
                exit ${FAILURE}
        fi
        TARGET_HOST=${LAST_RES_VALUE}
        write_log ${LOGFILE} "Copying ${ORA_USER}.TAB_${MYSTS} table from ${SOURCE_TNS} to ${TARGET_TNS}"

echo "
declare
        vDP Number ;
        vJState varchar2(100);
        vVal    varchar2(30);
begin
        select count(*) into vDP from user_db_links where lower(db_link) like lower('${SOURCE_TNS}.%') ;
        if vDP > 0 then
                execute immediate 'drop database link ${SOURCE_TNS}' ;
        end if;
        execute immediate 'create database link ${SOURCE_TNS}
                           connect to ${ORA_USER} identified by ${ORA_PASSWORD}
                           using ''${SOURCE_TNS}'' ';
        select upper(value) into vVal from v\$parameter where name='global_names' ;
        if vVal = 'TRUE' then
                execute immediate 'alter system set global_names=false scope=memory';
        end if;
        execute immediate 'select count(*) from dual@${SOURCE_TNS}' into vDP ;
        vDP := sys.dbms_datapump.open(operation => 'IMPORT', job_mode => 'TABLE', remote_link => '${SOURCE_TNS}', version=> 'COMPATIBLE') ;
        sys.dbms_datapump.metadata_filter(handle=>vDP,name=>'NAME_LIST',value=>'''TAB_${MYSTS}''');
        sys.dbms_datapump.set_parameter(handle=>vDP, name=>'TABLE_EXISTS_ACTION', value=>'REPLACE') ;
--              sys.dbms_datapump.add_file(handle => vDP, filename => 'myststab_i.log',
--                                               directory => 'LOGDIR', filetype => SYS.DBMS_DATAPUMP.KU\$_FILE_TYPE_LOG_FILE);
        sys.dbms_datapump.start_job(handle=>vDP);
        sys.dbms_datapump.wait_for_job(handle=>vDP, job_state => vJState);
        if vVal = 'TRUE' then
                execute immediate 'alter system set global_names=true scope=memory';
        end if;
        if upper(vJState) <> 'COMPLETED' then
                sys.dbms_datapump.detach(vDP);
                raise_application_error(-20101,'ERROR: Importing table TAB_${MYSTS} ..');
        end if;
end;
/"      > ${TEMPFILE}
        exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
        if [[ $? -ne ${SUCCESS} ]]; then
                write_log ${LOGFILE} "ERROR: Copying SQLTuning Set.."
                cat ${SQLRES} | tee -a ${LOGFILE}
                exit ${FAILURE}
        fi
        write_log ${LOGFILE} "Successfully Copied ${ORA_USER}.TAB_${MYSTS} table from ${SOURCE_TNS} to ${TARGET_TNS}"

echo "
begin
 -- Temporary Workaround to New Bug with Numeric Overflow error.
 execute immediate 'update ${ORA_USER}.TAB_${MYSTS} set EXECUTIONS = 999999999 where EXECUTIONS > 999999999';
 commit;
 for i in (select id from DBA_SQLSET_REFERENCES
                   where SQLSET_NAME='${MYSTS}' and SQLSET_OWNER='${ORA_USER}')
 loop
                sys.dbms_sqltune.REMOVE_SQLSET_REFERENCE('${MYSTS}', i.id );
 end loop;
 for i in (select name, OWNER from DBA_SQLSET where name = '${MYSTS}' and owner='${ORA_USER}')
 loop
                sys.dbms_sqltune.DELETE_SQLSET(sqlset_name=>i.name,sqlset_owner=>i.owner);
 end loop;
 sys.dbms_sqltune.unpack_stgtab_sqlset(
        sqlset_name => '${MYSTS}',
        sqlset_owner => '${ORA_USER}',
        replace => true,
        staging_table_name => 'TAB_${MYSTS}',
        staging_schema_owner => '${ORA_USER}');
end;
/"      > ${TEMPFILE}
        exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
                if [[ $? -ne ${SUCCESS} ]]; then
                                write_log ${LOGFILE} "ERROR: Unpacking SQLTuning Set.."
                                cat ${SQLRES} | tee -a ${LOGFILE}
                                exit ${FAILURE}
                fi
        write_log ${LOGFILE} "Successfully Unpacked SQL Tuning Set ${MYSTS} on ${TARGET_TNS}"
fi

if [[ "${GENERATE_REPORT}" = "${YESWORD}" ]]; then
        ## Execute/Analyze the task and generate report
        write_log ${LOGFILE} "Executing Comprehensive performance analyzer task and generating report"
echo "
declare t_name VARCHAR2(100);
        vCnt   pls_integer;
        vTaskId Number;
begin
   select count(*) into vCnt from dba_advisor_tasks where task_name = 'SPA_${MYSTS}' ;
   if vCnt > 0 then
        dbms_sqlpa.DROP_ANALYSIS_TASK('SPA_${MYSTS}');
   end if;
   t_name := dbms_sqlpa.create_analysis_task(
                sqlset_name => '${MYSTS}',
                sqlset_owner => '${ORA_USER}',
                task_name => 'SPA_${MYSTS}');
   dbms_sqlpa.execute_analysis_task(
        task_name => 'SPA_${MYSTS}',
        execution_type => 'CONVERT SQLSET',
        execution_name => 'pre');
   dbms_sqlpa.execute_analysis_task(
        task_name => 'SPA_${MYSTS}',
        execution_type => 'TEST EXECUTE',
        execution_name => 'post');
   select task_id into vTaskId from dba_advisor_tasks where task_name = 'SPA_${MYSTS}' ;
   vCnt := 1;
   while vCnt > 0 loop
        sys.dbms_lock.sleep(10);
        select count(*) into vCnt from v\$advisor_progress where task_id = vTaskId and SOFAR < TOTALWORK;
   end loop;
   dbms_sqlpa.execute_analysis_task(
        task_name => 'SPA_${MYSTS}',
        execution_name => 'compare_pre_post_ela',
        execution_type => 'COMPARE PERFORMANCE',
        execution_params => dbms_advisor.arglist(
                'COMPARISON_METRIC', 'ELAPSED_TIME',
                        'EXECUTION_NAME1', 'pre',
                                'EXECUTION_NAME2', 'post'),
        execution_desc => 'Compare SQLs performance source Vs target'
       );
end;
/
"       > ${TEMPFILE}
        exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
                if [[ $? -ne ${SUCCESS} ]]; then
                                write_log ${LOGFILE} "ERROR: Executing/Analyzing SQLPA pre/post performance.."
                                cat ${SQLRES} | tee -a ${LOGFILE}
                                exit ${FAILURE}
                fi
        write_log ${LOGFILE} "Successfully Executed Comprehensive Analysis of SQL PA Task SPA_${MYSTS} on ${TARGET_TNS}"

echo "
        set heading off long 1000000000 longchunksize 10000 echo off verify off feedback off;
        set linesize 1000 trimspool on pagesize 0;
                set termout off;
        variable cap_id number;
        exec :cap_id:= dbms_workload_capture.get_capture_info(dir=>'DIR_${MYSTS}');
        exec dbms_workload_capture.export_awr(capture_id=>:cap_id);
        variable cap_rpt clob;
        exec :cap_rpt := dbms_workload_capture.report(capture_id=>:cap_id, format=> dbms_workload_capture.type_html);
        spool ${ORCL_LOGDIR}/rat_capture_${SOURCE_TNS}.html
        select :cap_rpt from dual;
        spool off
"       > ${TEMPFILE}
        write_log ${LOGFILE} "Exporting the AWR snapshots associated with a given capture ID for ${SOURCE_TNS}"
        write_log ${LOGFILE} "Generating RAT Capture report.. at ${SOURCE_TNS} "
        exec_sql_file "${ORA_USER}" "${ORA_PASSWORD}" "${SOURCE_TNS}" "${TEMPFILE}"
                if [[ $? -ne ${SUCCESS} ]]; then
                                write_log ${LOGFILE} "ERROR: Generating RAT Capture report.."
                                cat ${SQLRES} | tee -a ${LOGFILE}
                                exit ${FAILURE}
                fi
                write_log ${LOGFILE} "Successfully Generated RAT Capture Report on ${SOURCE_TNS}"
        write_log ${LOGFILE} "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
        write_log ${LOGFILE} "Reports Can be Found @ "
        write_log ${LOGFILE} "                       ${ORCL_LOGDIR}/rat_capture${SOURCE_TNS}.html"
        write_log ${LOGFILE} "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"

        write_log ${LOGFILE} "Generating the Comprehensive Analysis SQL PA report .."

echo "
        set heading off long 1000000000 longchunksize 10000 echo off verify off feedback off;
        set linesize 1000 trimspool on pagesize 0;
                set termout off;
                spool ${ORCL_LOGDIR}/spa_errors_${TARGET_TNS}.html
        select xmltype(
                dbms_sqlpa.report_analysis_task(
                    'SPA_${MYSTS}','HTML','ERRORS','ALL',NULL,10,execution_name=>'compare_pre_post_ela')
                     ).getclobval(0,0)
        from dual;
        spool off
        spool ${ORCL_LOGDIR}/spa_unsupported_${TARGET_TNS}.html
        select xmltype(
                dbms_sqlpa.report_analysis_task(
                        'SPA_${MYSTS}','HTML','UNSUPPORTED','ALL',NULL,10,execution_name=>'compare_pre_post_ela')
                        ).getclobval(0,0)
        from dual;
        spool off
        spool ${ORCL_LOGDIR}/spa_active_${TARGET_TNS}.html
        select xmltype(
                dbms_sqlpa.report_analysis_task(
                        'SPA_${MYSTS}','ACTIVE','ALL',execution_name=>'compare_pre_post_ela')
                        ).getclobval(0,0)
        from dual;
        spool off

        spool ${ORCL_LOGDIR}/spa_regressed_${TARGET_TNS}.html
        select xmltype(
                dbms_sqlpa.report_analysis_task(
                        'SPA_${MYSTS}','HTML','REGRESSED','ALL',NULL,10,execution_name=>'compare_pre_post_ela')
                        ).getclobval(0,0)
        from dual;
        spool off

        spool ${ORCL_LOGDIR}/spa_changed_plans_${TARGET_TNS}.html
        select xmltype(
                dbms_sqlpa.report_analysis_task(
                        'SPA_${MYSTS}','HTML','CHANGED_PLANS','ALL',NULL,10,execution_name=>'compare_pre_post_ela')
                        ).getclobval(0,0)
        from dual;
        spool off

        spool ${ORCL_LOGDIR}/spa_improved_${TARGET_TNS}.html
        select xmltype(
                dbms_sqlpa.report_analysis_task(
                        'SPA_${MYSTS}','HTML','IMPROVED','ALL',NULL,10,execution_name=>'compare_pre_post_ela')
                        ).getclobval(0,0)
        from dual;
        spool off
"       > ${TEMPFILE}
        exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
                if [[ $? -ne ${SUCCESS} ]]; then
                                write_log ${LOGFILE} "ERROR: Generating SQLPA pre/post report.."
                                cat ${SQLRES} | tee -a ${LOGFILE}
                                exit ${FAILURE}
                fi
                write_log ${LOGFILE} "Successfully Generated Comprehensive Analysis Report of SQL PA Task SPA_${MYSTS} on ${TARGET_TNS}"
        write_log ${LOGFILE} "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
        write_log ${LOGFILE} "Reports Can be Found @ "
        write_log ${LOGFILE} "                       ${ORCL_LOGDIR}/spa_ela_${TARGET_TNS}.html"
        write_log ${LOGFILE} "                       ${ORCL_LOGDIR}/spa_errors_${TARGET_TNS}.html"
        write_log ${LOGFILE} "                       ${ORCL_LOGDIR}/spa_unsupported_${TARGET_TNS}.html"
        write_log ${LOGFILE} "                       ${ORCL_LOGDIR}/spa_active_${TARGET_TNS}.html"
        write_log ${LOGFILE} "                       ${ORCL_LOGDIR}/spa_regressed_${TARGET_TNS}.html"
        write_log ${LOGFILE} "                       ${ORCL_LOGDIR}/spa_changed_plans_${TARGET_TNS}.html"
        write_log ${LOGFILE} "                       ${ORCL_LOGDIR}/spa_improved_${TARGET_TNS}.html"
        write_log ${LOGFILE} "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
fi


}
#
##  Replay
##
#

function replay

{

if [ ! -d "${ORCL_LOGDIR}/rat" ]; then
#    rm -r ${ORCL_LOGDIR}/rat
    mkdir -p ${ORCL_LOGDIR}/rat
#else
#     mkdir -p ${ORCL_LOGDIR}/rat
fi


if [[ -n "${TARGET_TNS}" ]]; then # removed to by pass minutes test && ${DURATION} -gt 0
echo "
DECLARE
   vCnt_replay    pls_integer;
   vDir  varchar2(2000) := concat('${ORCL_LOGDIR}','/replay');
   vName varchar2(100) ;
   vStatus_replay varchar2(100) ;
   vReplay_id pls_integer;
   vSysdate date;

BEGIN
    select count(*) into vCnt_replay from dba_workload_replays where STATUS in ('INITIALIZED','IN PROGRESS','PREPARE ') ;

    if vCnt_replay > 0 then
        raise_application_error(-20101,'ERROR: Replay already in progress ..');
    end if;

    select 'RAT_REPLAY_DIR' into vName from dual ;
    execute immediate 'create or replace directory '||vName||' as '||chr(39)||vDir||chr(39) ;

    select count(*) into vCnt_replay from dba_workload_replays where STATUS in ('INITIALIZED','IN PROGRESS','PREPARE ') ;

    if vCnt_replay =0 Then
        dbms_workload_replay.process_capture('RAT_REPLAY_DIR');
                        execute immediate 'CREATE RESTORE POINT B4_REPLAY GUARANTEE FLASHBACK DATABASE';
        dbms_workload_replay.initialize_replay('REPLAY_T1','RAT_REPLAY_DIR');
    end if;

   vReplay_id:= dbms_workload_replay.get_replay_info(replay_dir => 'RAT_REPLAY_DIR');
     SELECT MAX (id) INTO vReplay_id FROM dba_workload_replays WHERE capture_id = vReplay_id;
   select STATUS into vStatus_replay from dba_workload_replays where ID=vReplay_id;

   if vStatus_replay = 'INITIALIZED' then
        dbms_workload_replay.prepare_replay();
  end if;
 END;
/
" > ${TEMPFILE}
write_log ${LOGFILE} "Pre processing the workload capture for ${SOURCE_TNS} and preparing to replay in  ${TARGET_TNS} "
exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
if [[ $? -ne ${SUCCESS} ]]; then
        write_log ${LOGFILE} "ERROR: processing the Captured workload.."
        cat ${SQLRES} | tee -a ${LOGFILE}
        exit ${FAILURE}
fi
write_log ${LOGFILE} "RAT  workload capture processed and initialized successfully"
fi

vREPLAYDIR=${ORCL_LOGDIR}"/replay"
#add vREPLAYDIR exists check
#ssh -t "${TARGET_HOST}" ". ./${TARGET_TNS}.env;wrc mode=calibrate replaydir=${vREPLAYDIR}"
#"${TARGET_HOST}" ". ./${TARGET_TNS}.env;wrc mode=calibrate replaydir=${vREPLAYDIR}"
wrc "${TORA_USER}"/"${TORA_PASSWORD}"@"${TARGET_TNS}" mode=calibrate replaydir="${vREPLAYDIR}"

write_log ${LOGFILE} "Open putty client sessions as per the Recommendation"
write_log ${LOGFILE} "Use below command from each putty session - it connects to the database and gets ready to start the replay"
write_log ${LOGFILE} "wrc ${ORA_USER}/password@${TARGET_TNS} mode=replay replaydir=${vREPLAYDIR} CONNECTION_OVERRIDE=TRUE"
write_log ${LOGFILE} "Once WRC clients are connected come back to START the replay . Please press y/Y to continue .."
vReplay_status=0
read opt_upg
if [ "$opt_upg" ==  "y" ] || [ "$opt_upg" ==  "Y" ] ; then
echo "
DECLARE
   vCnt_replay_sess    pls_integer;
   vCnt_rat                     pls_integer;
BEGIN
    select count(*) into vCnt_replay_sess from gv\$session where program like 'wrc%' ;

    if vCnt_replay_sess = 0 then
        raise_application_error(-20102,'ERROR: wrc clients not started ..');
     else
         dbms_workload_replay.start_replay;
    end if;
 END;
/
" > ${TEMPFILE}
write_log ${LOGFILE} "Initiating to replay the workload in  ${TARGET_TNS} "
exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
if [[ $? -ne ${SUCCESS} ]]; then
        write_log ${LOGFILE} "ERROR: cannot initiate workload replay..Review and retry"
        cat ${SQLRES} | tee -a ${LOGFILE}
        exit ${FAILURE}
fi
write_log ${LOGFILE} "RAT : workload replay initiated successfully"
vReplay_status=1
fi

if [ "$vReplay_status" ==  1 ]  ; then
echo "
DECLARE
   vCnt_rat                     pls_integer;
BEGIN
vCnt_rat := 1;
   while vCnt_rat > 0 loop
        sys.dbms_lock.sleep(10);
        select count(*) into vCnt_rat from dba_workload_replays where STATUS = 'IN PROGRESS' ;
   end loop;
 END;
/
" > ${TEMPFILE}
write_log ${LOGFILE} "RAT: Replay of workload in  ${TARGET_TNS} is IN PROGRESS.. "
exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
if [[ $? -ne ${SUCCESS} ]]; then
        write_log ${LOGFILE} "ERROR: workload replay aborted , please verify the logs"
        cat ${SQLRES} | tee -a ${LOGFILE}
        exit ${FAILURE}
fi
write_log ${LOGFILE} "RAT : workload replay completed successfully"
vReplay_status=2
fi

if [ "$vReplay_status" ==  2 ]  ; then
echo " alter session set events '31151 trace name context forever, level 0x40000';
SET HEADING OFF LONG 1000000000 LONGCHUNKSIZE 10000 ECHO OFF VERIFY OFF FEEDBACK OFF
           SET LINESIZE 1000 TRIMSPOOL ON PAGESIZE 0
           SET PAGESIZE 0 TRIMSPOOL ON LINESIZE 500 FEEDBACK OFF LONG 999999999 SERVEROUTPUT ON
           SET TERMOUT OFF
                VAR vReplay_compare_rpt CLOB;
                DECLARE
                vReplay_id             number;
                vMax_Replay_id         number;
                vCapid                 number;
                vCur                               CLOB;
                BEGIN
                vCapid := dbms_workload_capture.get_capture_info(dir => 'RAT_REPLAY_DIR');
                select dbms_workload_capture.import_awr (capture_id => vCapid ,staging_schema => '${ORA_USER}') into vCur from dual;
                vReplay_id :=  dbms_workload_replay.get_replay_info(replay_dir => 'RAT_REPLAY_DIR');
                SELECT MAX (id) INTO vMax_Replay_id FROM dba_workload_replays where capture_id = vReplay_id;
                dbms_workload_replay.compare_period_report (replay_id1 =>vMax_Replay_id,replay_id2 => NULL, format =>DBMS_WORKLOAD_CAPTURE.TYPE_HTML, result =>:vReplay_compare_rpt);
                END;
                /
                spool ${ORCL_LOGDIR}/replay_compare${TARGET_TNS}.html
                print vReplay_compare_rpt
                spool off
          " > ${TEMPFILE}
          write_log ${LOGFILE} "RAT: Generating Replay and comparision report.. "
          exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
          if [[ $? -ne ${SUCCESS} ]]; then
                        write_log ${LOGFILE} "ERROR: workload replay report generation , please verify the logs"
                        cat ${SQLRES} | tee -a ${LOGFILE}
                        exit ${FAILURE}
          fi
          write_log ${LOGFILE} "RAT : workload replay comparision reports generated successfully"
fi

if [ "$vReplay_status" ==  2 ]  ; then
 echo "SET HEADING OFF LONG 1000000000 LONGCHUNKSIZE 10000 ECHO OFF VERIFY OFF FEEDBACK OFF
           SET LINESIZE 1000 TRIMSPOOL ON PAGESIZE 0
           SET PAGESIZE 0 TRIMSPOOL ON LINESIZE 500 FEEDBACK OFF LONG 999999999 SERVEROUTPUT ON
           SET TERMOUT OFF
                VAR vReplay_rpt CLOB
                DECLARE
                vReplay_id number;
                vMax_Replay_id number;
                BEGIN
                vReplay_id :=  DBMS_WORKLOAD_REPLAY.GET_REPLAY_INFO(replay_dir => 'RAT_REPLAY_DIR');
                SELECT MAX (id) INTO vMax_Replay_id FROM dba_workload_replays where capture_id = vReplay_id;
                :vReplay_rpt := DBMS_WORKLOAD_REPLAY.REPORT(replay_id =>vMax_Replay_id, format =>DBMS_WORKLOAD_REPLAY.TYPE_HTML);
                END;
                /
                spool ${ORCL_LOGDIR}/replay_${TARGET_TNS}.html
                print vReplay_rpt
                spool off
                "> ${TEMPFILE}
       write_log ${LOGFILE} "Generating RAT Replay report.. at ${TARGET_TNS} "
       exec_sql_file "${TORA_USER}" "${TORA_PASSWORD}" "${TARGET_TNS}" "${TEMPFILE}"
               if [[ $? -ne ${SUCCESS} ]]; then
                               write_log ${LOGFILE} "ERROR: Generating RAT Replay report.."
                               cat ${SQLRES} | tee -a ${LOGFILE}
                               exit ${FAILURE}
               fi
               write_log ${LOGFILE} "Successfully Generated RAT Replay Report on ${TARGET_TNS}"
       write_log ${LOGFILE} "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
       write_log ${LOGFILE} "Reports Can be Found @ "
       write_log ${LOGFILE} "                       ${ORCL_LOGDIR}/rat_replay${TARGET_TNS}.html"
        write_log ${LOGFILE} "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
fi

}

## END # Setup Functions #

trap "trap_cleanup" EXIT STOP TERM KILL
trap "exit" INT
